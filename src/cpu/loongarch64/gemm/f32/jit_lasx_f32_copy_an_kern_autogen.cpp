/*******************************************************************************
* Copyright 2019-2021 Intel Corporation
*
* Licensed under the Apache License, Version 2.0 (the "License");
* you may not use this file except in compliance with the License.
* You may obtain a copy of the License at
*
*     http://www.apache.org/licenses/LICENSE-2.0
*
* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an "AS IS" BASIS,
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
* See the License for the specific language governing permissions and
* limitations under the License.
*******************************************************************************/

#include "cpu/loongarch64/jit_generator.hpp"

#include "cpu/loongarch64/gemm/f32/common_f32.hpp"

namespace dnnl {
namespace impl {
namespace cpu {
namespace loongarch64 {

jit_lasx_f32_copy_an_kern::jit_lasx_f32_copy_an_kern()
    : jit_generator(nullptr, F32_COPY_KERNEL_CODE_SIZE) {}

void jit_lasx_f32_copy_an_kern::generate() {

#define M a0//rdi
#define N a1//rsi
#define A a2//rdx
#define LDA a3//rcx
#define ALPHA a4//r8
#define B a5//r9

#define I t5//rax
#define A1 t6//r10
#define A2 a4//r8
#define LDA3 t7//r11
#define LDA4 t4//new add
#define LDA8 t8//new add
#define TM s1
#define TM0 s0

    inLocalLabel();
    {
        std::vector<Xbyak_loongarch64::Label> labels(113);

        preamble();

        ld_d(M, M, 0);
        ld_d(N, N, 0);
        ld_d(LDA, LDA, 0);
        addi_d(A, A, 128);
        addi_d(B, B, 128);
        slli_d(LDA, LDA, 0x2);
        slli_d(LDA4, LDA, 2);
        sub_d(LDA3, LDA4, LDA);
        add_d(LDA8, LDA4, LDA4);
        xvldrepl_w(xr6, ALPHA, 0);
        vseq_b(vr3, vr3, vr3);
        vsrli_w(vr3, vr3, 0x17);
        vslli_w(vr3, vr3, 0x19);
        vsrli_w(vr3, vr3, 0x2);
        vseq_b(vr4, vr4, vr4);
        vslli_w(vr4, vr4, 0x1f);
        xvpermi_q(xr4, xr4, 0x20);
        vfcmp_cle_s(vr31, vr3, vr6);
        vpickve2gr_w(TM, vr31, 0);
        bnez(TM, labels[102]);
        mov_imm(TM, 0x18);
        blt(N, TM, labels[69]);

        L(labels[74]);
        add_d(A1, A, zero);
        add_d(A2, A1, LDA4);
        addi_d(A, A, 0x60);
        srai_d(I, M, 0x3);
        bge(zero, I, labels[49]);

        L(labels[84]);
        xvld(xr0, A1, -0x80);
        xvst(xr0, B, -0x80);
        xvld(xr0, A1, -0x60);
        xvst(xr0, B, -0x60);
        xvld(xr0, A1, -0x40);
        xvst(xr0, B, -0x40);
        add_d(TM, A1, LDA);
        xvld(xr0, TM, -0x80);
        xvst(xr0, B, -0x20);
        xvld(xr0, TM, -0x60);
        xvst(xr0, B, 0);
        xvld(xr0, TM, -0x40);
        xvst(xr0, B, 0x20);
        add_d(TM, TM, LDA);
        xvld(xr0, TM, -0x80);
        xvst(xr0, B, 0x40);
        xvld(xr0, TM, -0x60);
        xvst(xr0, B, 0x60);
        xvld(xr0, TM, -0x40);
        xvst(xr0, B, 0x80);
        add_d(TM, A1, LDA3);
        xvld(xr0, TM, -0x80);
        xvst(xr0, B, 0xa0);
        xvld(xr0, TM, -0x60);
        xvst(xr0, B, 0xc0);
        xvld(xr0, TM, -0x40);
        xvst(xr0, B, 0xe0);
        xvld(xr0, A2, -0x80);
        xvst(xr0, B, 0x100);
        xvld(xr0, A2, -0x60);
        xvst(xr0, B, 0x120);
        xvld(xr0, A2, -0x40);
        xvst(xr0, B, 0x140);
        add_d(TM, A2, LDA);
        xvld(xr0, TM, -0x80);
        xvst(xr0, B, 0x160);
        xvld(xr0, TM, -0x60);
        xvst(xr0, B, 0x180);
        xvld(xr0, TM, -0x40);
        xvst(xr0, B, 0x1a0);
        add_d(TM, TM, LDA);
        xvld(xr0, TM, -0x80);
        xvst(xr0, B, 0x1c0);
        xvld(xr0, TM, -0x60);
        xvst(xr0, B, 0x1e0);
        xvld(xr0, TM, -0x40);
        xvst(xr0, B, 0x200);
        add_d(TM, A2, LDA3);
        xvld(xr0, TM, -0x80);
        xvst(xr0, B, 0x220);
        xvld(xr0, TM, -0x60);
        xvst(xr0, B, 0x240);
        xvld(xr0, TM, -0x40);
        xvst(xr0, B, 0x260);
        add_d(A1, A1, LDA8);
        add_d(A2, A2, LDA8);
        addi_d(B, B, 768);
        addi_d(I, I, -1);
        blt(zero, I, labels[84]);

        L(labels[49]);
        andi(TM, M, 0x4);
        bge(zero, TM, labels[66]);
        xvld(xr0, A1, -0x80);
        xvst(xr0, B, 0x80);
        xvld(xr0, A1, -0x60);
        xvst(xr0, B, -0x60);
        xvld(xr0, A1, -0x40);
        xvst(xr0, B, 0x40);
        add_d(TM, A1, LDA);
        xvld(xr0, TM, -0x80);
        xvst(xr0, B, -0x20);
        xvld(xr0, TM, -0x60);
        xvst(xr0, B, 0);
        xvld(xr0, TM, -0x40);
        xvst(xr0, B, 0x20);
        add_d(TM, TM, LDA);
        xvld(xr0, TM, -0x80);
        xvst(xr0, B, 0x40);
        xvld(xr0, TM, -0x60);
        xvst(xr0, B, 0x60);
        xvld(xr0, TM, -0x40);
        xvst(xr0, B, 0x80);
        add_d(TM, A1, LDA3);
        xvld(xr0, TM, -0x80);
        xvst(xr0, B, 0xa0);
        xvld(xr0, TM, -0x60);
        xvst(xr0, B, 0xc0);
        xvld(xr0, TM, -0x40);
        xvst(xr0, B, 0xe0);
        add_d(A1, A1, LDA4);
        addi_d(B, B, 384);

        L(labels[66]);
        andi(TM, M, 0x2);
        bge(zero, TM, labels[67]);
        xvld(xr0, A1, -0x80);
        xvst(xr0, B, -0x80);
        xvld(xr0, A1, -0x60);
        xvst(xr0, B, -0x60);
        xvld(xr0, A1, -0x40);
        xvst(xr0, B, -0x40);
        add_d(TM, A1, LDA);
        xvld(xr0, TM, -0x80);
        xvst(xr0, B, -0x20);
        xvld(xr0, TM, -0x60);
        xvst(xr0, B, 0);
        xvld(xr0, TM, -0x40);
        xvst(xr0, B, 0x20);
        add_d(A1, TM, LDA);
        addi_d(B, B, 192);

        L(labels[67]);
        andi(TM, M, 0x1);
        bge(zero, TM, labels[68]);
        xvld(xr0, A1, -0x80);
        xvst(xr0, B, -0x80);
        xvld(xr0, A1, -0x60);
        xvst(xr0, B, -0x60);
        xvld(xr0, A1, -0x40);
        xvst(xr0, B, -0x40);
        addi_d(B, B, 96);

        L(labels[68]);
        addi_d(N, N, -0x18);
        mov_imm(TM, 0x18);
        bge(N, TM, labels[74]);

        L(labels[69]);
        mov_imm(TM, 0x10);
        blt(N, TM, labels[76]);
        add_d(A1, A, zero);
        add_d(A2, A1, LDA4);
        addi_d(A, A, 0x40);
        srai_d(I, M, 0x3);
        bge(zero, I, labels[71]);

        L(labels[70]);
        xvld(xr0, A1, -0x80);
        xvst(xr0, B, -0x80);
        xvld(xr0, A1, -0x60);
        xvst(xr0, B, -0x60);
        add_d(TM, A1, LDA);
        xvld(xr0, TM, -0x80);
        xvst(xr0, B, -0x40);
        xvld(xr0, TM, -0x60);
        xvst(xr0, B, -0x20);
        add_d(TM, TM, LDA);
        xvld(xr0, TM, -0x80);
        xvst(xr0, B, 0);
        xvld(xr0, TM, -0x60);
        xvst(xr0, B, 0x20);
        add_d(TM, A1, LDA3);
        xvld(xr0, TM, -0x80);
        xvst(xr0, B, 0x40);
        xvld(xr0, TM, -0x60);
        xvst(xr0, B, 0x60);
        xvld(xr0, A2, -0x80);
        xvst(xr0, B, 0x80);
        xvld(xr0, A2, -0x60);
        xvst(xr0, B, 0xa0);
        add_d(TM, A2, LDA);
        xvld(xr0, TM, -0x80);
        xvst(xr0, B, 0xc0);
        xvld(xr0, TM, -0x60);
        xvst(xr0, B, 0xe0);
        add_d(TM, TM, LDA);
        xvld(xr0, TM, -0x80);
        xvst(xr0, B, 0x100);
        xvld(xr0, TM, -0x60);
        xvst(xr0, B, 0x120);
        add_d(TM, A2, LDA3);
        xvld(xr0, TM, -0x80);
        xvst(xr0, B, 0x140);
        xvld(xr0, TM, -0x60);
        xvst(xr0, B, 0x160);
        add_d(A1, A1, LDA8);
        add_d(A2, A2, LDA8);
        addi_d(B, B, 512);
        addi_d(I, I, -1);
        blt(zero, I, labels[70]);

        L(labels[71]);
        andi(TM, M, 0x4);
        bge(zero, TM, labels[72]);
        xvld(xr0, A1, -0x80);
        xvst(xr0, B, -0x80);
        xvld(xr0, A1, -0x60);
        xvst(xr0, B, -0x60);
        add_d(TM, A1, LDA);
        xvld(xr0, TM, -0x80);
        xvst(xr0, B, -0x40);
        xvld(xr0, TM, -0x60);
        xvst(xr0, B, -0x20);
        add_d(TM, TM, LDA);
        xvld(xr0, TM, -0x80);
        xvst(xr0, B, 0);
        xvld(xr0, TM, -0x60);
        xvst(xr0, B, 0x20);
        add_d(TM, A1, LDA3);
        xvld(xr0, TM, -0x80);
        xvst(xr0, B, 0x40);
        xvld(xr0, TM, -0x60);
        xvst(xr0, B, 0x60);
        add_d(A1, A1, LDA4);
        addi_d(B, B, 256);

        L(labels[72]);
        andi(TM, M, 0x2);
        bge(zero, TM, labels[73]);
        xvld(xr0, A1, -0x80);
        xvst(xr0, B, -0x80);
        xvld(xr0, A1, -0x60);
        xvst(xr0, B, -0x60);
        add_d(TM, A1, LDA);
        xvld(xr0, TM, -0x80);
        xvst(xr0, B, -0x40);
        xvld(xr0, TM, -0x60);
        xvst(xr0, B, -0x20);
        add_d(A1, TM, LDA);
        addi_d(B, B, 128);

        L(labels[73]);
        andi(TM, M, 0x1);
        bge(zero, TM, labels[75]);
        xvld(xr0, A1, -0x80);
        xvst(xr0, B, -0x80);
        xvld(xr0, A1, -0x60);
        xvst(xr0, B, -0x60);
        addi_d(B, B, 64);

        L(labels[75]);
        addi_d(N, N, -0x10);

        L(labels[76]);
        mov_imm(TM, 0x8);
        blt(N, TM, labels[82]);
        add_d(A1, A, zero);
        add_d(A2, A1, LDA4);
        addi_d(A, A, 0x20);
        srai_d(I, M, 0x3);
        bge(zero, I, labels[78]);

        L(labels[77]);
        xvld(xr0, A1, -0x80);
        xvst(xr0, B, -0x80);
        add_d(TM, A1, LDA);
        xvld(xr0, TM, -0x80);
        xvst(xr0, B, -0x60);
        add_d(TM, TM, LDA);
        xvld(xr0, TM, -0x80);
        xvst(xr0, B, -0x40);
        add_d(TM, A1, LDA3);
        xvld(xr0, TM, -0x80);
        xvst(xr0, B, -0x20);
        xvld(xr0, A2, -0x80);
        xvst(xr0, B, 0);
        add_d(TM, A2, LDA);
        xvld(xr0, TM, -0x80);
        xvst(xr0, B, 0x20);
        add_d(TM, TM, LDA);
        xvld(xr0, TM, -0x80);
        xvst(xr0, B, 0x40);
        add_d(TM, A2, LDA3);
        xvld(xr0, TM, -0x80);
        xvst(xr0, B, 0x60);
        add_d(A1, A1, LDA8);
        add_d(A2, A2, LDA8);
        addi_d(B, B, 256);
        addi_d(I, I, -1);
        blt(zero, I, labels[77]);

        L(labels[78]);
        andi(TM, M, 0x4);
        bge(zero, TM, labels[79]);
        xvld(xr0, A1, -0x80);
        xvst(xr0, B, -0x80);
        add_d(TM, A1, LDA);
        xvld(xr0, TM, -0x80);
        xvst(xr0, B, -0x60);
        add_d(TM, TM, LDA);
        xvld(xr0, TM, -0x80);
        xvst(xr0, B, -0x40);
        add_d(TM, A1, LDA3);
        xvld(xr0, TM, -0x80);
        xvst(xr0, B, -0x20);
        add_d(A1, A1, LDA4);
        addi_d(B, B, 128);

        L(labels[79]);
        andi(TM, M, 0x2);
        bge(zero, TM, labels[80]);
        xvld(xr0, A1, -0x80);
        xvst(xr0, B, -0x80);
        add_d(TM, A1, LDA);
        xvld(xr0, TM, -0x80);
        xvst(xr0, B, -0x60);
        add_d(A1, TM, LDA);
        addi_d(B, B, 64);

        L(labels[80]);
        andi(TM, M, 0x1);
        bge(zero, TM, labels[81]);
        xvld(xr0, A1, -0x80);
        xvst(xr0, B, -0x80);
        addi_d(B, B, 32);

        L(labels[81]);
        addi_d(N, N, -0x8);

        L(labels[82]);
        mov_imm(TM, 0x4);
        blt(N, TM, labels[89]);
        add_d(A1, A, zero);
        add_d(A2, A1, LDA4);
        addi_d(A, A, 0x10);
        srai_d(I, M, 0x3);
        bge(zero, I, labels[85]);

        L(labels[83]);
        vld(vr0, A1, -0x80);
        vst(vr0, B, -0x80);
        add_d(TM, A1, LDA);
        vld(vr0, TM, -0x80);
        vst(vr0, B, -0x70);
        add_d(TM, TM, LDA);
        vld(vr0, TM, -0x80);
        vst(vr0, B, -0x60);
        add_d(TM, A1, LDA3);
        vld(vr0, TM, -0x80);
        vst(vr0, B, -0x50);
        vld(vr0, A2, -0x80);
        vst(vr0, B, -0x40);
        add_d(TM, A2, LDA);
        vld(vr0, TM, -0x80);
        vst(vr0, B, -0x30);
        add_d(TM, TM, LDA);
        vld(vr0, TM, -0x80);
        vst(vr0, B, -0x20);
        add_d(TM, A2, LDA3);
        vld(vr0, TM, -0x80);
        vst(vr0, B, -0x10);
        add_d(A1, A1, LDA8);
        add_d(A2, A2, LDA8);
        addi_d(B, B, 128);
        addi_d(I, I, -1);
        blt(zero, I, labels[83]);

        L(labels[85]);
        andi(TM, M, 0x4);
        bge(zero, TM, labels[86]);
        vld(vr0, A1, -0x80);
        vst(vr0, B, -0x80);
        add_d(TM, A1, LDA);
        vld(vr0, TM, -0x80);
        vst(vr0, B, -0x70);
        add_d(TM, TM, LDA);
        vld(vr0, TM, -0x80);
        vst(vr0, B, -0x60);
        add_d(TM, A1, LDA3);
        vld(vr0, TM, -0x80);
        vst(vr0, B, -0x50);
        add_d(A1, A1, LDA4);
        addi_d(B, B, 64);

        L(labels[86]);
        andi(TM, M, 0x2);
        bge(zero, TM, labels[87]);
        vld(vr0, A1, -0x80);
        vst(vr0, B, -0x80);
        add_d(TM, A1, LDA);
        vld(vr0, TM, -0x80);
        vst(vr0, B, -0x70);
        add_d(A1, TM, LDA);
        addi_d(B, B, 32);

        L(labels[87]);
        andi(TM, M, 0x1);
        bge(zero, TM, labels[88]);
        vld(vr0, A1, -0x80);
        vst(vr0, B, -0x80);
        addi_d(B, B, 16);

        L(labels[88]);
        addi_d(N, N, -0x4);

        L(labels[89]);
        mov_imm(TM, 0x2);
        blt(N, TM, labels[95]);
        add_d(A1, A, zero);
        add_d(A2, A1, LDA4);
        addi_d(A, A, 0x8);
        srai_d(I, M, 0x3);
        bge(zero, I, labels[91]);

        L(labels[90]);
        ld_d(TM0, A1, -0x80);
        st_d(TM0, B, -0x80);
        add_d(TM, A1, LDA);
        ld_d(TM0, TM, -0x80);
        st_d(TM0, B, -0x78);
        add_d(TM, TM, LDA);
        ld_d(TM0, TM, -0x80);
        st_d(TM0, B, -0x70);
        add_d(TM, A1, LDA3);
        ld_d(TM0, TM, -0x80);
        st_d(TM0, B, -0x68);
        ld_d(TM0, A2, -0x80);
        st_d(TM0, B, -0x60);
        add_d(TM, A2, LDA);
        ld_d(TM0, TM, -0x80);
        st_d(TM0, B, -0x58);
        add_d(TM, TM, LDA);
        ld_d(TM0, TM, -0x80);
        st_d(TM0, B, -0x50);
        add_d(TM, A2, LDA3);
        ld_d(TM0, TM, -0x80);
        st_d(TM0, B, -0x48);
        add_d(A1, A1, LDA8);
        add_d(A2, A2, LDA8);
        addi_d(B, B, 64);
        addi_d(I, I, -1);
        blt(zero, I, labels[90]);

        L(labels[91]);
        andi(TM, M, 0x4);
        bge(zero, TM, labels[92]);
        ld_d(TM0, A1, -0x80);
        st_d(TM0, B, -0x80);
        add_d(TM, A1, LDA);
        ld_d(TM0, TM, -0x80);
        st_d(TM0, B, -0x78);
        add_d(TM, TM, LDA);
        ld_d(TM0, TM, -0x80);
        st_d(TM0, B, -0x70);
        add_d(TM, A1, LDA3);
        ld_d(TM0, TM, -0x80);
        st_d(TM0, B, -0x68);
        add_d(A1, A1, LDA4);
        addi_d(B, B, 32);

        L(labels[92]);
        andi(TM, M, 0x2);
        bge(zero, TM, labels[93]);
        ld_d(TM0, A1, -0x80);
        st_d(TM0, B, -0x80);
        add_d(TM, A1, LDA);
        ld_d(TM0, TM, -0x80);
        st_d(TM0, B, -0x78);
        add_d(A1, TM, LDA);
        addi_d(B, B, 16);

        L(labels[93]);
        andi(TM, M, 0x1);
        bge(zero, TM, labels[94]);
        ld_d(TM0, A1, -0x80);
        st_d(TM0, B, -0x80);
        addi_d(B, B, 8);

        L(labels[94]);
        addi_d(N, N, -0x2);

        L(labels[95]);
        mov_imm(TM, 0x1);
        blt(N, TM, labels[101]);
        add_d(A1, A, zero);
        add_d(A2, A1, LDA4);
        addi_d(A, A, 0x4);
        srai_d(I, M, 0x3);
        bge(zero, I, labels[97]);

        L(labels[96]);
        ld_w(TM0, A1, -0x80);
        st_w(TM0, B, -0x80);
        add_d(TM, A1, LDA);
        ld_w(TM0, TM, -0x80);
        st_w(TM0, B, -0x7c);
        add_d(TM, TM, LDA);
        ld_w(TM0, TM, -0x80);
        st_w(TM0, B, -0x78);
        add_d(TM, A1, LDA3);
        ld_w(TM0, TM, -0x80);
        st_w(TM0, B, -0x74);
        ld_w(TM0, A2, -0x80);
        st_w(TM0, B, -0x70);
        add_d(TM, A2, LDA);
        ld_w(TM0, TM, -0x80);
        st_w(TM0, B, -0x6c);
        add_d(TM, TM, LDA);
        ld_w(TM0, TM, -0x80);
        st_w(TM0, B, -0x68);
        add_d(TM, A2, LDA3);
        ld_w(TM0, TM, -0x80);
        st_w(TM0, B, -0x64);
        add_d(A1, A1, LDA8);
        add_d(A2, A2, LDA8);
        addi_d(B, B, 32);
        addi_d(I, I, -1);
        blt(zero, I, labels[96]);

        L(labels[97]);
        andi(TM, M, 0x4);
        bge(zero, TM, labels[98]);
        ld_w(TM0, A1, -0x80);
        st_w(TM0, B, -0x80);
        add_d(TM, A1, LDA);
        ld_w(TM0, TM, -0x80);
        st_w(TM0, B, -0x7c);
        add_d(TM, TM, LDA);
        ld_w(TM0, TM, -0x80);
        st_w(TM0, B, -0x78);
        add_d(TM, A1, LDA3);
        ld_w(TM0, TM, -0x80);
        st_w(TM0, B, -0x74);
        add_d(A1, A1, LDA4);
        addi_d(B, B, 16);

        L(labels[98]);
        andi(TM, M, 0x2);
        bge(zero, TM, labels[99]);
        ld_w(TM0, A1, -0x80);
        st_w(TM0, B, -0x80);
        add_d(TM, A1, LDA);
        ld_w(TM0, TM, -0x80);
        st_w(TM0, B, -0x7c);
        add_d(A1, TM, LDA);
        addi_d(B, B, 8);

        L(labels[99]);
        andi(TM, M, 0x1);
        bge(zero, TM, labels[100]);
        ld_w(TM0, A1, -0x80);
        st_w(TM0, B, -0x80);
        addi_d(B, B, 4);

        L(labels[100]);
        addi_d(N, N, -1);

        L(labels[101]);
        b(labels[65]);

        L(labels[102]);
        vxor_v(vr3, vr3, vr4);
        vfcmp_cle_s(vr31, vr3, vr6);
        vpickve2gr_w(TM, vr31, 0);
        bnez(TM, labels[27]);
        xvbsll_v(xr6, xr4, 0);
        mov_imm(TM, 0x18);
        blt(N, TM, labels[109]);

        L(labels[103]);
        add_d(A1, A, zero);
        add_d(A2, A1, LDA4);
        addi_d(A, A, 0x60);
        srai_d(I, M, 0x3);
        bge(zero, I, labels[105]);

        L(labels[104]);
        xvld(xr0, A1, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, -0x80);
        xvld(xr0, A1, -0x60);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, -0x60);
        xvld(xr0, A1, -0x40);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, -0x40);
        add_d(TM, A1, LDA);
        xvld(xr0, TM, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, -0x20);
        xvld(xr0, TM, -0x60);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0);
        xvld(xr0, TM, -0x40);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0x20);
        add_d(TM, TM, LDA);
        xvld(xr0, TM, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0x40);
        xvld(xr0, TM, -0x60);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0x60);
        xvld(xr0, TM, -0x40);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0x80);
        add_d(TM, A1, LDA3);
        xvld(xr0, TM, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0xa0);
        xvld(xr0, TM, -0x60);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0xc0);
        xvld(xr0, TM, -0x40);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0xe0);
        xvld(xr0, A2, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0x100);
        xvld(xr0, A2, -0x60);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0x120);
        xvld(xr0, A2, -0x40);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0x140);
        add_d(TM, A2, LDA);
        xvld(xr0, TM, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0x160);
        xvld(xr0, TM, -0x60);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0x180);
        xvld(xr0, TM, -0x40);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0x1a0);
        add_d(TM, TM, LDA);
        xvld(xr0, TM, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0x1c0);
        xvld(xr0, TM, -0x60);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0x1e0);
        xvld(xr0, TM, -0x40);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0x200);
        add_d(TM, A2, LDA3);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0x220);
        xvld(xr0, TM, -0x60);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0x240);
        xvld(xr0, TM, -0x40);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0x260);
        add_d(A1, A1, LDA8);
        add_d(A2, A2, LDA8);
        addi_d(B, B, 768);
        addi_d(I, I, -1);
        blt(zero, I, labels[104]);

        L(labels[105]);
        andi(TM, M, 0x4);
        bge(zero, TM, labels[106]);
        xvld(xr0, A1, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, -0x80);
        xvld(xr0, A1, -0x60);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, -0x60);
        xvld(xr0, A1, -0x40);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, -0x40);
        add_d(TM, A1, LDA);
        xvld(xr0, TM, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, -0x20);
        xvld(xr0, TM, -0x60);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0);
        xvld(xr0, TM, -0x40);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0x20);
        add_d(TM, TM, LDA);
        xvld(xr0, TM, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0x40);
        xvld(xr0, TM, -0x60);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0x60);
        xvld(xr0, TM, -0x40);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0x80);
        add_d(TM, A1, LDA3);
        xvld(xr0, TM, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0xa0);
        xvld(xr0, TM, -0x60);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0xc0);
        xvld(xr0, TM, -0x40);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0xe0);
        add_d(A1, A1, LDA4);
        addi_d(B, B, 384);

        L(labels[106]);
        andi(TM, M, 0x2);
        bge(zero, TM, labels[107]);
        xvld(xr0, A1, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, -0x80);
        xvld(xr0, A1, -0x60);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, -0x60);
        xvld(xr0, A1, -0x40);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, -0x40);
        add_d(TM, A1, LDA);
        xvld(xr0, TM, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, -0x20);
        xvld(xr0, TM, -0x60);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0);
        xvld(xr0, TM, -0x40);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0x20);
        add_d(A1, TM, LDA);
        addi_d(B, B, 192);

        L(labels[107]);
        andi(TM, M, 0x1);
        bge(zero, TM, labels[108]);
        xvld(xr0, A1, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, -0x80);
        xvld(xr0, A1, -0x60);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, -0x60);
        xvld(xr0, A1, -0x40);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, -0x40);
        addi_d(B, B, 96);

        L(labels[108]);
        addi_d(N, N, -0x18);
        mov_imm(TM, 0x18);
        bge(N, TM, labels[103]);

        L(labels[109]);
        mov_imm(TM, 0x10);
        blt(N, TM, labels[2]);
        add_d(A1, A, zero);
        add_d(A2, A1, LDA4);
        addi_d(A, A, 0x40);
        srai_d(I, M, 0x3);
        bge(zero, I, labels[111]);

        L(labels[110]);
        xvld(xr0, A1, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, -0x80);
        xvld(xr0, A1, -0x60);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, -0x60);
        add_d(TM, A1, LDA);
        xvld(xr0, TM, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, -0x40);
        xvld(xr0, TM, -0x60);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, -0x20);
        add_d(TM, TM, LDA);
        xvld(xr0, TM, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0);
        xvld(xr0, TM, -0x60);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0x20);
        add_d(TM, A1, LDA3);
        xvld(xr0, TM, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0x40);
        xvld(xr0, TM, -0x60);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0x60);
        xvld(xr0, A2, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0x80);
        xvld(xr0, A2, -0x60);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0xa0);
        add_d(TM, A2, LDA);
        xvld(xr0, TM, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0xc0);
        xvld(xr0, TM, -0x60);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0xe0);
        add_d(TM, TM, LDA);
        xvld(xr0, TM, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0x100);
        xvld(xr0, TM, -0x60);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0x120);
        add_d(TM, A2, LDA3);
        xvld(xr0, TM, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0x140);
        xvld(xr0, TM, -0x60);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0x160);
        add_d(A1, A1, LDA8);
        add_d(A2, A2, LDA8);
        addi_d(B, B, 512);
        addi_d(I, I, -1);
        blt(zero, I, labels[110]);

        L(labels[111]);
        andi(TM, M, 0x4);
        bge(zero, TM, labels[112]);
        xvld(xr0, A1, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, -0x80);
        xvld(xr0, A1, -0x60);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, -0x60);
        add_d(TM, A1, LDA);
        xvld(xr0, TM, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, -0x40);
        xvld(xr0, TM, -0x60);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, -0x20);
        add_d(TM, TM, LDA);
        xvld(xr0, TM, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0);
        xvld(xr0, TM, -0x60);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0x20);
        add_d(TM, A1, LDA3);
        xvld(xr0, TM, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0x40);
        xvld(xr0, TM, -0x60);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0x60);
        add_d(A1, A1, LDA4);
        addi_d(B, B, 256);

        L(labels[112]);
        andi(TM, M, 0x2);
        bge(zero, TM, labels[0]);
        xvld(xr0, A1, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, -0x80);
        xvld(xr0, A1, -0x60);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, -0x60);
        add_d(TM, A1, LDA);
        xvld(xr0, TM, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, -0x40);
        xvld(xr0, TM, -0x60);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, -0x20);
        add_d(A1, TM, LDA);
        addi_d(B, B, 128);

        L(labels[0]);
        andi(TM, M, 0x1);
        bge(zero, TM, labels[1]);
        xvld(xr0, A1, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, -0x80);
        xvld(xr0, A1, -0x60);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, -0x60);
        addi_d(B, B, 64);

        L(labels[1]);
        addi_d(N, N, -0x10);

        L(labels[2]);
        mov_imm(TM, 0x8);
        blt(N, TM, labels[8]);
        add_d(A1, A, zero);
        add_d(A2, A1, LDA4);
        addi_d(A, A, 0x20);
        srai_d(I, M, 0x3);
        bge(zero, I, labels[4]);

        L(labels[3]);
        xvld(xr0, A1, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, -0x80);
        add_d(TM, A1, LDA);
        xvld(xr0, TM, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, -0x60);
        add_d(TM, TM, LDA);
        xvld(xr0, TM, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, -0x40);
        add_d(TM, A1, LDA3);
        xvld(xr0, TM, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, -0x20);
        xvld(xr0, A2, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0);
        add_d(TM, A2, LDA);
        xvld(xr0, TM, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0x20);
        add_d(TM, TM, LDA);
        xvld(xr0, TM, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0x40);
        add_d(TM, A2, LDA3);
        xvld(xr0, TM, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, 0x60);
        add_d(A1, A1, LDA8);
        add_d(A2, A2, LDA8);
        addi_d(B, B, 256);
        addi_d(I, I, -1);
        blt(zero, I, labels[3]);

        L(labels[4]);
        andi(TM, M, 0x4);
        bge(zero, TM, labels[5]);
        xvld(xr0, A1, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, -0x80);
        add_d(TM, A1, LDA);
        xvld(xr0, TM, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, -0x60);
        add_d(TM, TM, LDA);
        xvld(xr0, TM, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, -0x40);
        add_d(TM, A1, LDA3);
        xvld(xr0, TM, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, -0x20);
        add_d(A1, A1, LDA4);
        addi_d(B, B, 128);

        L(labels[5]);
        andi(TM, M, 0x2);
        bge(zero, TM, labels[6]);
        xvld(xr0, A1, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, -0x80);
        add_d(TM, A1, LDA);
        xvld(xr0, TM, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, -0x60);
        add_d(A1, TM, LDA);
        addi_d(B, B, 64);

        L(labels[6]);
        andi(TM, M, 0x1);
        bge(zero, TM, labels[7]);
        xvld(xr0, A1, -0x80);
        xvxor_v(xr0, xr6, xr0);
        xvst(xr0, B, -0x80);
        addi_d(B, B, 32);

        L(labels[7]);
        addi_d(N, N, -0x8);

        L(labels[8]);
        mov_imm(TM, 4);
        blt(N, TM, labels[14]);
        add_d(A1, A, zero);
        add_d(A2, A1, LDA4);
        addi_d(A, A, 0x10);
        srai_d(I, M, 0x3);
        bge(zero, I, labels[10]);

        L(labels[9]);
        vld(vr0, A1, -0x80);
        vxor_v(vr0, vr6, vr0);
        vst(vr0, B, -0x80);
        add_d(TM, A1, LDA);
        vld(vr0, TM, -0x80);
        vxor_v(vr0, vr6, vr0);
        vst(vr0, B, -0x70);
        add_d(TM, TM, LDA);
        vld(vr0, TM, -0x80);
        vxor_v(vr0, vr6, vr0);
        vst(vr0, B, -0x60);
        add_d(TM, A1, LDA3);
        vld(vr0, TM, -0x80);
        vxor_v(vr0, vr6, vr0);
        vst(vr0, B, -0x50);
        vld(vr0, A2, -0x80);
        vxor_v(vr0, vr6, vr0);
        vst(vr0, B, -0x40);
        add_d(TM, A2, LDA);
        vld(vr0, TM, -0x80);
        vxor_v(vr0, vr6, vr0);
        vst(vr0, B, -0x30);
        add_d(TM, TM, LDA);
        vld(vr0, TM, -0x80);
        vxor_v(vr0, vr6, vr0);
        vst(vr0, B, -0x20);
        add_d(TM, A2, LDA3);
        vld(vr0, TM, -0x80);
        vxor_v(vr0, vr6, vr0);
        vst(vr0, B, -0x10);
        add_d(A1, A1, LDA8);
        add_d(A2, A2, LDA8);
        addi_d(B, B, 128);
        addi_d(I, I, -1);
        blt(zero, I, labels[9]);

        L(labels[10]);
        andi(TM, M, 0x4);
        bge(zero, TM, labels[11]);
        vld(vr0, A1, -0x80);
        vxor_v(vr0, vr6, vr0);
        vst(vr0, B, -0x80);
        add_d(TM, A1, LDA);
        vld(vr0, TM, -0x80);
        vxor_v(vr0, vr6, vr0);
        vst(vr0, B, -0x70);
        add_d(TM, TM, LDA);
        vld(vr0, TM, -0x80);
        vxor_v(vr0, vr6, vr0);
        vst(vr0, B, -0x60);
        add_d(TM, A1, LDA3);
        vld(vr0, TM, -0x80);
        vxor_v(vr0, vr6, vr0);
        vst(vr0, B, -0x50);
        add_d(A1, A1, LDA4);
        addi_d(B, B, 64);

        L(labels[11]);
        andi(TM, M, 0x2);
        bge(zero, TM, labels[12]);
        vld(vr0, A1, -0x80);
        vxor_v(vr0, vr6, vr0);
        vst(vr0, B, -0x80);
        add_d(TM, A1, LDA);
        vld(vr0, TM, -0x80);
        vxor_v(vr0, vr6, vr0);
        vst(vr0, B, -0x70);
        add_d(A1, TM, LDA);
        addi_d(B, B, 32);

        L(labels[12]);
        andi(TM, M, 0x1);
        bge(zero, TM, labels[13]);
        vld(vr0, A1, -0x80);
        vxor_v(vr0, vr6, vr0);
        vst(vr0, B, -0x80);
        addi_d(B, B, 16);

        L(labels[13]);
        addi_d(N, N, -4);

        L(labels[14]);
        mov_imm(TM, 0x2);
        blt(N, TM, labels[20]);
        add_d(A1, A, zero);
        add_d(A2, A1, LDA4);
        addi_d(A, A, 0x8);
        srai_d(I, M, 0x3);
        bge(zero, I, labels[16]);

        L(labels[15]);
        vld(vr0, A1, -0x80);
        vxor_v(vr0, vr6, vr0);
        vstelm_d(vr0, B, -0x80, 0);
        add_d(TM, A1, LDA);
        vld(vr0, TM, -0x80);
        vxor_v(vr0, vr6, vr0);
        vstelm_d(vr0, B, -0x78, 0);
        add_d(TM, TM, LDA);
        vld(vr0, TM, -0x80);
        vxor_v(vr0, vr6, vr0);
        vstelm_d(vr0, B, -0x70, 0);
        add_d(TM, A1, LDA3);
        vld(vr0, TM, -0x80);
        vxor_v(vr0, vr6, vr0);
        vstelm_d(vr0, B, -0x68, 0);
        vld(vr0, A2, -0x80);
        vxor_v(vr0, vr6, vr0);
        vstelm_d(vr0, B, -0x60, 0);
        add_d(TM, A2, LDA);
        vld(vr0, TM, -0x80);
        vxor_v(vr0, vr6, vr0);
        vstelm_d(vr0, B, -0x58, 0);
        add_d(TM, TM, LDA);
        vld(vr0, TM, -0x80);
        vxor_v(vr0, vr6, vr0);
        vstelm_d(vr0, B, -0x50, 0);
        add_d(TM, A2, LDA3);
        vld(vr0, TM, -0x80);
        vxor_v(vr0, vr6, vr0);
        vstelm_d(vr0, B, -0x48, 0);
        add_d(A1, A1, LDA8);
        add_d(A2, A2, LDA8);
        addi_d(B, B, 64);
        addi_d(I, I, -1);
        blt(zero, I, labels[15]);

        L(labels[16]);
        andi(TM, M, 0x4);
        bge(zero, TM, labels[17]);
        vld(vr0, A1, -0x80);
        vxor_v(vr0, vr6, vr0);
        vstelm_d(vr0, B, -0x80, 0);
        add_d(TM, A1, LDA);
        vld(vr0, TM, -0x80);
        vxor_v(vr0, vr6, vr0);
        vstelm_d(vr0, B, -0x78, 0);
        add_d(TM, TM, LDA);
        vld(vr0, TM, -0x80);
        vxor_v(vr0, vr6, vr0);
        vstelm_d(vr0, B, -0x70, 0);
        add_d(TM, A1, LDA3);
        vld(vr0, TM, -0x80);
        vxor_v(vr0, vr6, vr0);
        vstelm_d(vr0, B, -0x68, 0);
        add_d(A1, A1, LDA4);
        addi_d(B, B, 32);

        L(labels[17]);
        andi(TM, M, 0x2);
        bge(zero, TM, labels[18]);
        vld(vr0, A1, -0x80);
        vxor_v(vr0, vr6, vr0);
        vstelm_d(vr0, B, -0x80, 0);
        add_d(TM, A1, LDA);
        vld(vr0, TM, -0x80);
        vxor_v(vr0, vr6, vr0);
        vstelm_d(vr0, B, -0x78, 0);
        add_d(A1, TM, LDA);
        addi_d(B, B, 16);

        L(labels[18]);
        andi(TM, M, 0x1);
        bge(zero, TM, labels[19]);
        vld(vr0, A1, -0x80);
        vxor_v(vr0, vr6, vr0);
        vstelm_d(vr0, B, -0x80, 0);
        addi_d(B, B, 8);

        L(labels[19]);
        addi_d(N, N, -0x2);

        L(labels[20]);
        mov_imm(TM, 0x1);
        blt(N, TM, labels[26]);
        add_d(A1, A, zero);
        add_d(A2, A1, LDA4);
        addi_d(A, A, 0x4);
        srai_d(I, M, 0x3);
        bge(zero, I, labels[22]);

        L(labels[21]);
        vld(vr0, A1, -0x80);
        vxor_v(vr0, vr6, vr0);
        vstelm_w(vr0, B, -0x80, 0);
        add_d(TM, A1, LDA);
        vld(vr0, TM, -0x80);
        vxor_v(vr0, vr6, vr0);
        vstelm_w(vr0, B, -0x7c, 0);
        add_d(TM, TM, LDA);
        vld(vr0, TM, -0x80);
        vxor_v(vr0, vr6, vr0);
        vstelm_w(vr0, B, -0x78, 0);
        add_d(TM, A1, LDA3);
        vld(vr0, TM, -0x80);
        vxor_v(vr0, vr6, vr0);
        vstelm_w(vr0, B, -0x74, 0);
        vld(vr0, A2, -0x80);
        vxor_v(vr0, vr6, vr0);
        vstelm_w(vr0, B, -0x70, 0);
        add_d(TM, A2, LDA);
        vld(vr0, TM, -0x80);
        vxor_v(vr0, vr6, vr0);
        vstelm_w(vr0, B, -0x6c, 0);
        add_d(TM, TM, LDA);
        vld(vr0, TM, -0x80);
        vxor_v(vr0, vr6, vr0);
        vstelm_w(vr0, B, -0x68, 0);
        add_d(TM, A2, LDA3);
        vld(vr0, TM, -0x80);
        vxor_v(vr0, vr6, vr0);
        vstelm_w(vr0, B, -0x64, 0);
        add_d(A1, A1, LDA8);
        add_d(A2, A2, LDA8);
        addi_d(B, B, 32);
        addi_d(I, I, -1);
        blt(zero, I, labels[21]);

        L(labels[22]);
        andi(TM, M, 0x4);
        bge(zero, TM, labels[23]);
        vld(vr0, A1, -0x80);
        vxor_v(vr0, vr6, vr0);
        vstelm_w(vr0, B, -0x80, 0);
        add_d(TM, A1, LDA);
        vld(vr0, TM, -0x80);
        vxor_v(vr0, vr6, vr0);
        vstelm_w(vr0, B, -0x7c, 0);
        add_d(TM, TM, LDA);
        vld(vr0, TM, -0x80);
        vxor_v(vr0, vr6, vr0);
        vstelm_w(vr0, B, -0x78, 0);
        add_d(TM, A1, LDA3);
        vld(vr0, TM, -0x80);
        vxor_v(vr0, vr6, vr0);
        vstelm_w(vr0, B, -0x74, 0);
        add_d(A1, A1, LDA4);
        addi_d(B, B, 16);

        L(labels[23]);
        andi(TM, M, 0x2);
        bge(zero, TM, labels[24]);
        vld(vr0, A1, -0x80);
        vxor_v(vr0, vr6, vr0);
        vstelm_w(vr0, B, -0x80, 0);
        add_d(TM, A1, LDA);
        vld(vr0, TM, -0x80);
        vxor_v(vr0, vr6, vr0);
        vstelm_w(vr0, B, -0x7c, 0);
        add_d(A1, TM, LDA);
        addi_d(B, B, 8);

        L(labels[24]);
        andi(TM, M, 0x1);
        bge(zero, TM, labels[25]);
        vld(vr0, A1, -0x80);
        vxor_v(vr0, vr6, vr0);
        vstelm_w(vr0, B, -0x80, 0);
        addi_d(B, B, 4);

        L(labels[25]);
        addi_d(N, N, -0x1);

        L(labels[26]);
        b(labels[65]);

        L(labels[27]);
        mov_imm(TM, 0x18);
        blt(N, TM, labels[34]);

        L(labels[28]);
        add_d(A1, A, zero);
        add_d(A2, A1, LDA4);
        addi_d(A, A, 0x60);
        srai_d(I, M, 0x3);
        bge(zero, I, labels[30]);

        L(labels[29]);
        xvld(xr0, A1, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, -0x80);
        xvld(xr0, A1, -0x60);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, -0x60);
        xvld(xr0, A1, -0x40);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, -0x40);
        add_d(TM, A1, LDA);
        xvld(xr0, TM, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, -0x20);
        xvld(xr0, TM, -0x60);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0);
        xvld(xr0, TM, -0x40);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0x20);
        add_d(TM, TM, LDA);
        xvld(xr0, TM, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0x40);
        xvld(xr0, TM, -0x60);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0x60);
        xvld(xr0, TM, -0x40);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0x80);
        add_d(TM, A1, LDA3);
        xvld(xr0, TM, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0xa0);
        xvld(xr0, TM, -0x60);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0xc0);
        xvld(xr0, TM, -0x40);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0xe0);
        xvld(xr0, A2, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0x100);
        xvld(xr0, A2, -0x60);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0x120);
        xvld(xr0, A2, -0x40);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0x140);
        add_d(TM, A2, LDA);
        xvld(xr0, TM, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0x160);
        xvld(xr0, TM, -0x60);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0x180);
        xvld(xr0, TM, -0x40);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0x1a0);
        add_d(TM, TM, LDA);
        xvld(xr0, TM, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0x1c0);
        xvld(xr0, TM, -0x60);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0x1e0);
        xvld(xr0, TM, -0x40);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0x200);
        add_d(TM, A2, LDA3);
        xvld(xr0, TM, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0x220);
        xvld(xr0, TM, -0x60);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0x240);
        xvld(xr0, TM, -0x40);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0x260);
        add_d(A1, A1, LDA8);
        add_d(A2, A2, LDA8);
        addi_d(B, B, 768);
        addi_d(I, I, -1);
        blt(zero, I, labels[29]);

        L(labels[30]);
        andi(TM, M, 0x4);
        bge(zero, TM, labels[31]);
        xvld(xr0, A1, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, -0x80);
        xvld(xr0, A1, -0x60);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, -0x60);
        xvld(xr0, A1, -0x40);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, -0x40);
        add_d(TM, A1, LDA);
        xvld(xr0, TM, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, -0x20);
        xvld(xr0, TM, -0x60);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0);
        xvld(xr0, TM, -0x40);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0x20);
        add_d(TM, TM, LDA);
        xvld(xr0, TM, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0x40);
        xvld(xr0, TM, -0x60);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0x60);
        xvld(xr0, TM, -0x40);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0x80);
        add_d(TM, A1, LDA3);
        xvld(xr0, TM, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0xa0);
        xvld(xr0 ,TM, -0x60);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0xc0);
        xvld(xr0, TM, -0x40);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0xe0);
        add_d(A1, A1, LDA4);
        addi_d(B, B, 384);

        L(labels[31]);
        andi(TM, M, 0x2);
        bge(zero, TM, labels[32]);
        xvld(xr0, A1, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, -0x80);
        xvld(xr0, A1, -0x60);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, -0x60);
        xvld(xr0, A1, -0x40);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, -0x40);
        add_d(TM, A1, LDA);
        xvld(xr0, TM, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, -0x20);
        xvld(xr0, TM, -0x60);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0);
        xvld(xr0, TM, -0x40);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0x20);
        add_d(A1, TM, LDA);
        addi_d(B, B, 192);

        L(labels[32]);
        andi(TM, M, 0x1);
        bge(zero, TM, labels[33]);
        xvld(xr0, A1, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, -0x80);
        xvld(xr0, A1, -0x60);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, -0x60);
        xvld(xr0, A1, -0x40);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, -0x40);
        addi_d(B, B, 96);

        L(labels[33]);
        addi_d(N, N, -0x18);
        mov_imm(TM, 0x18);
        bge(N, TM, labels[28]);

        L(labels[34]);
        mov_imm(TM, 0x10);
        blt(N, TM, labels[40]);
        add_d(A1, A, zero);
        add_d(A2, A1, LDA4);
        addi_d(A, A, 0x40);
        srai_d(I, M, 0x3);
        bge(zero, I, labels[36]);

        L(labels[35]);
        xvld(xr0, A1, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, -0x80);
        xvld(xr0, A1, -0x60);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, -0x60);
        add_d(TM, A1, LDA);
        xvld(xr0, TM, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, -0x40);
        xvld(xr0, TM, -0x60);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, -0x20);
        add_d(TM, TM, LDA);
        xvld(xr0, TM, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0);
        xvld(xr0, TM, -0x60);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0x20);
        add_d(TM, A1, LDA3);
        xvld(xr0, TM, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0x40);
        xvld(xr0, TM, -0x60);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0x60);
        xvld(xr0, A2, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0x80);
        xvld(xr0, A2, -0x60);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0xa0);
        add_d(TM, A2, LDA);
        xvld(xr0, TM, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0xc0);
        xvld(xr0, TM, -0x60);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0xe0);
        add_d(TM, TM, LDA);
        xvld(xr0, TM, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0x100);
        xvld(xr0, TM, -0x60);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0x120);
        add_d(TM, A2, LDA3);
        xvld(xr0, TM, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0x140);
        xvld(xr0, TM, -0x60);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0x160);
        add_d(A1, A1, LDA8);
        add_d(A2, A2, LDA8);
        addi_d(B, B, 512);
        addi_d(I, I, -1);
        blt(zero, I, labels[35]);

        L(labels[36]);
        andi(TM, M, 0x4);
        bge(zero, TM, labels[37]);
        xvld(xr0, A1, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, -0x80);
        xvld(xr0, A1, -0x60);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, -0x60);
        add_d(TM, A1, LDA);
        xvld(xr0, TM, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, -0x40);
        xvld(xr0, TM, -0x60);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, -0x20);
        add_d(TM, TM, LDA);
        xvld(xr0, TM, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0);
        xvld(xr0, TM, -0x60);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0x20);
        add_d(TM, A1, LDA3);
        xvld(xr0, TM, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0x40);
        xvld(xr0, TM, -0x60);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0x60);
        add_d(A1, A1, LDA4);
        addi_d(B, B, 256);

        L(labels[37]);
        andi(TM, M, 0x2);
        bge(zero, TM, labels[38]);
        xvld(xr0, A1, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, -0x80);
        xvld(xr0, A1, -0x60);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, -0x60);
        add_d(TM, A1, LDA);
        xvld(xr0, TM, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, -0x40);
        xvld(xr0, TM, -0x60);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, -0x20);
        add_d(A1, TM, LDA);
        addi_d(B, B, 128);

        L(labels[38]);
        andi(TM, M, 0x1);
        bge(zero, TM, labels[39]);
        xvld(xr0, A1, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, -0x80);
        xvld(xr0, A1, -0x60);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, -0x60);
        addi_d(B, B, 64);

        L(labels[39]);
        addi_d(N, N, -0x10);

        L(labels[40]);
        mov_imm(TM, 0x8);
        blt(N, TM, labels[46]);
        add_d(A1, A, zero);
        add_d(A2, A1, LDA4);
        addi_d(A, A, 0x20);
        srai_d(I, M, 0x3);
        bge(zero, I, labels[42]);

        L(labels[41]);
        xvld(xr0, A1, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, -0x80);
        add_d(TM, A1, LDA);
        xvld(xr0, TM, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, -0x60);
        add_d(TM, TM, LDA);
        xvld(xr0, TM, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, -0x40);
        add_d(TM, A1, LDA3);
        xvld(xr0, TM, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, -0x20);
        xvld(xr0, A2, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0);
        add_d(TM, A2, LDA);
        xvld(xr0, TM, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0x20);
        add_d(TM, TM, LDA);
        xvld(xr0, TM, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0x40);
        add_d(TM, A2, LDA3);
        xvld(xr0, TM, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, 0x60);
        add_d(A1, A1, LDA8);
        add_d(A2, A2, LDA8);
        addi_d(B, B, 256);
        addi_d(I, I, -1);
        blt(zero, I, labels[41]);

        L(labels[42]);
        andi(TM, M, 0x4);
        bge(zero, TM, labels[43]);
        xvld(xr0, A1, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, -0x80);
        add_d(TM, A1, LDA);
        xvld(xr0, TM, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, -0x60);
        add_d(TM, TM, LDA);
        xvld(xr0, TM, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, -0x40);
        add_d(TM, A1, LDA3);
        xvld(xr0, TM, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, -0x20);
        add_d(A1, A1, LDA4);
        addi_d(B, B, 128);

        L(labels[43]);
        andi(TM, M, 0x2);
        bge(zero, TM, labels[44]);
        xvld(xr0, A1, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, -0x80);
        add_d(TM, A1, LDA);
        xvld(xr0, TM, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, -0x60);
        add_d(A1, TM, LDA);
        addi_d(B, B, 64);

        L(labels[44]);
        andi(TM, M, 0x1);
        bge(zero, TM, labels[45]);
        xvld(xr0, A1, -0x80);
        xvfmul_s(xr0, xr6, xr0);
        xvst(xr0, B, -0x80);
        addi_d(B, B, 32);

        L(labels[45]);
        addi_d(N, N, -0x8);

        L(labels[46]);
        mov_imm(TM, 0x4);
        blt(N, TM, labels[53]);
        add_d(A1, A, zero);
        add_d(A2, A1, LDA4);
        addi_d(A, A, 0x10);
        srai_d(I, M, 0x3);
        bge(zero, I, labels[48]);

        L(labels[47]);
        vld(vr0, A1, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vst(vr0, B, -0x80);
        add_d(TM, A1, LDA);
        vld(vr0, TM, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vst(vr0, B, -0x70);
        add_d(TM, TM, LDA);
        vld(vr0, TM, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vst(vr0, B, -0x60);
        add_d(TM, A1, LDA3);
        vld(vr0, TM, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vst(vr0, B, -0x50);
        vld(vr0, A2, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vst(vr0, B, -0x40);
        add_d(TM, A2, LDA);
        vld(vr0, TM, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vst(vr0, B, -0x30);
        add_d(TM, TM, LDA);
        vld(vr0, TM, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vst(vr0, B, -0x20);
        add_d(TM, A2, LDA3);
        vld(vr0, TM, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vst(vr0, B, -0x10);
        add_d(A1, A1, LDA8);
        add_d(A2, A2, LDA8);
        addi_d(B, B, 128);
        addi_d(I, I, -1);
        blt(zero, I, labels[47]);

        L(labels[48]);
        andi(TM, M, 0x4);
        bge(zero, TM, labels[50]);
        vld(vr0, A1, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vst(vr0, B, -0x80);
        add_d(TM, A1, LDA);
        vld(vr0, TM, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vst(vr0, B, -0x70);
        add_d(TM, TM, LDA);
        vld(vr0, TM, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vst(vr0, B, -0x60);
        add_d(TM, A1, LDA3);
        vld(vr0, TM, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vst(vr0, B, -0x50);
        add_d(A1, A1, LDA4);
        addi_d(B, B, 64);

        L(labels[50]);
        andi(TM, M, 0x2);
        bge(zero, TM, labels[51]);
        vld(vr0, A1, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vst(vr0, B, -0x80);
        add_d(TM, A1, LDA);
        vld(vr0, TM, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vst(vr0, B, -0x70);
        add_d(A1, TM, LDA);
        addi_d(B, B, 32);

        L(labels[51]);
        andi(TM, M, 0x1);
        bge(zero, TM, labels[52]);
        vld(vr0, A1, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vst(vr0, B, -0x80);
        addi_d(B, B, 16);

        L(labels[52]);
        addi_d(N, N, -0x4);

        L(labels[53]);
        mov_imm(TM, 0x2);
        blt(N, TM, labels[59]);
        add_d(A1, A, zero);
        add_d(A2, A1, LDA4);
        addi_d(A, A, 0x8);
        srai_d(I, M, 0x3);
        bge(zero, I, labels[55]);

        L(labels[54]);
        vld(vr0, A1, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vstelm_d(vr0, B, -0x80, 0);
        add_d(TM, A1, LDA);
        vld(vr0, TM, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vstelm_d(vr0, B, -0x78, 0);
        add_d(TM, TM, LDA);
        vld(vr0, TM, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vstelm_d(vr0, B, -0x70, 0);
        add_d(TM, A1, LDA3);
        vld(vr0, TM, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vstelm_d(vr0, B, -0x68, 0);
        vld(vr0, A2, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vstelm_d(vr0, B, -0x60, 0);
        add_d(TM, A2, LDA);
        vld(vr0, TM, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vstelm_d(vr0, B, -0x58, 0);
        add_d(TM, TM, LDA);
        vld(vr0, TM, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vstelm_d(vr0, B, -0x50, 0);
        add_d(TM, A2, LDA3);
        vld(vr0, TM, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vstelm_d(vr0, B, -0x48, 0);
        add_d(A1, A1, LDA8);
        add_d(A2, A2, LDA8);
        addi_d(B, B, 64);
        addi_d(I, I, -1);
        blt(zero, I, labels[54]);

        L(labels[55]);
        andi(TM, M, 0x4);
        bge(zero, TM, labels[56]);
        vld(vr0, A1, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vstelm_d(vr0, B, -0x80, 0);
        add_d(TM, A1, LDA);
        vld(vr0, TM, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vstelm_d(vr0, B, -0x78, 0);
        add_d(TM, TM, LDA);
        vld(vr0, TM, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vstelm_d(vr0, B, -0x70, 0);
        add_d(TM, A1, LDA3);
        vld(vr0, TM, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vstelm_d(vr0, B, -0x68, 0);
        add_d(A1, A1, LDA4);
        addi_d(B, B, 32);

        L(labels[56]);
        andi(TM, M, 0x2);
        bge(zero, TM, labels[57]);
        vld(vr0, A1, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vstelm_d(vr0, B, -0x80, 0);
        add_d(TM, A1, LDA);
        vld(vr0, TM, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vstelm_d(vr0, B, -0x78, 0);
        add_d(A1, TM, LDA);
        addi_d(B, B, 16);

        L(labels[57]);
        andi(TM, M, 0x1);
        bge(zero, TM, labels[58]);
        vld(vr0, A1, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vstelm_d(vr0, B, -0x80, 0);
        addi_d(B, B, 8);

        L(labels[58]);
        addi_d(N, N, -0x2);

        L(labels[59]);
        addi_d(TM, zero, 0x1);
        blt(N, TM, labels[65]);
        add_d(A1, A, zero);
        add_d(A2, A1, LDA4);
        addi_d(A, A, 0x4);
        srai_d(I, M, 0x3);
        bge(zero, I, labels[61]);

        L(labels[60]);
        vld(vr0, A1, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vstelm_w(vr0, B, -0x80, 0);
        add_d(TM, A1, LDA);
        vld(vr0, TM, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vstelm_w(vr0, B, -0x7c, 0);
        add_d(TM, TM, LDA);
        vld(vr0, TM, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vstelm_w(vr0, B, -0x78, 0);
        add_d(TM, A1, LDA3);
        vld(vr0, TM, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vstelm_w(vr0, B, -0x74, 0);
        vld(vr0, A2, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vstelm_w(vr0, B, -0x70, 0);
        add_d(TM, A2, LDA);
        vld(vr0, TM, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vstelm_w(vr0, B, -0x6c, 0);
        add_d(TM, TM, LDA);
        vld(vr0, TM, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vstelm_w(vr0, B, -0x68, 0);
        add_d(TM, A2, LDA3);
        vld(vr0, TM, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vstelm_w(vr0, B, -0x64, 0);
        add_d(A1, A1, LDA8);
        add_d(A2, A2, LDA8);
        addi_d(B, B, 32);
        addi_d(I, I, -1);
        blt(zero, I, labels[60]);

        L(labels[61]);
        andi(TM, M, 0x4);
        bge(zero, TM, labels[62]);
        vld(vr0, A1, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vstelm_w(vr0, B, -0x80, 0);
        add_d(TM, A1, LDA);
        vld(vr0, TM, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vstelm_w(vr0, B, -0x7c, 0);
        add_d(TM, TM, LDA);
        vld(vr0, TM, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vstelm_w(vr0, B, -0x78, 0);
        add_d(TM, A1, LDA3);
        vld(vr0, TM, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vstelm_w(vr0, B, -0x74, 0);
        add_d(A1, A1, LDA4);
        addi_d(B, B, 16);

        L(labels[62]);
        andi(TM, M, 0x2);
        bge(zero, TM, labels[63]);
        vld(vr0, A1, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vstelm_w(vr0, B, -0x80, 0);
        add_d(TM, A1, LDA);
        vld(vr0, TM, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vstelm_w(vr0, B, -0x7c, 0);
        add_d(A1, TM, LDA);
        addi_d(B, B, 8);

        L(labels[63]);
        andi(TM, M, 0x1);
        bge(zero, TM, labels[64]);
        vld(vr0, A1, -0x80);
        vfmul_s(vr0, vr6, vr0);
        vstelm_w(vr0, B, -0x80, 0);
        addi_d(B, B, 4);

        L(labels[64]);
        addi_d(N, N, -0x1);

        L(labels[65]);

        postamble();
    }
    outLocalLabel();

#undef M
#undef N
#undef A
#undef LDA
#undef ALPHA
#undef B
#undef I
#undef A1
#undef A2
#undef LDA3
#undef LDA4
#undef LDA8
#undef TM
#undef TM0
}

} // namespace loongarch64
} // namespace cpu
} // namespace impl
} // namespace dnnl
